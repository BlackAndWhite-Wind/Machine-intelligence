{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 开启gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) # cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据集\n",
    "dataset = FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义变分自编码器\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc2 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(400, 20)\n",
    "        self.fc4 = nn.Linear(20, 400)\n",
    "        self.fc5 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "\n",
    "vaeModel = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vaeModel.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20], Step [100/938], Reconst Loss: 26311.5723\n",
      "Epoch[1/20], Step [200/938], Reconst Loss: 20754.8359\n",
      "Epoch[1/20], Step [300/938], Reconst Loss: 19318.3438\n",
      "Epoch[1/20], Step [400/938], Reconst Loss: 19580.2500\n",
      "Epoch[1/20], Step [500/938], Reconst Loss: 18226.3809\n",
      "Epoch[1/20], Step [600/938], Reconst Loss: 18728.6445\n",
      "Epoch[1/20], Step [700/938], Reconst Loss: 19135.7773\n",
      "Epoch[1/20], Step [800/938], Reconst Loss: 17596.9258\n",
      "Epoch[1/20], Step [900/938], Reconst Loss: 17171.3770\n",
      "Epoch[2/20], Step [100/938], Reconst Loss: 16697.4844\n",
      "Epoch[2/20], Step [200/938], Reconst Loss: 17668.3398\n",
      "Epoch[2/20], Step [300/938], Reconst Loss: 17061.6836\n",
      "Epoch[2/20], Step [400/938], Reconst Loss: 17027.2617\n",
      "Epoch[2/20], Step [500/938], Reconst Loss: 16153.0156\n",
      "Epoch[2/20], Step [600/938], Reconst Loss: 15809.0986\n",
      "Epoch[2/20], Step [700/938], Reconst Loss: 17049.0430\n",
      "Epoch[2/20], Step [800/938], Reconst Loss: 16482.5586\n",
      "Epoch[2/20], Step [900/938], Reconst Loss: 16534.3945\n",
      "Epoch[3/20], Step [100/938], Reconst Loss: 16472.8242\n",
      "Epoch[3/20], Step [200/938], Reconst Loss: 16265.3076\n",
      "Epoch[3/20], Step [300/938], Reconst Loss: 16535.6914\n",
      "Epoch[3/20], Step [400/938], Reconst Loss: 16951.2461\n",
      "Epoch[3/20], Step [500/938], Reconst Loss: 15603.4492\n",
      "Epoch[3/20], Step [600/938], Reconst Loss: 15510.2637\n",
      "Epoch[3/20], Step [700/938], Reconst Loss: 15706.2988\n",
      "Epoch[3/20], Step [800/938], Reconst Loss: 16056.9688\n",
      "Epoch[3/20], Step [900/938], Reconst Loss: 16528.6016\n",
      "Epoch[4/20], Step [100/938], Reconst Loss: 15932.5400\n",
      "Epoch[4/20], Step [200/938], Reconst Loss: 15505.8125\n",
      "Epoch[4/20], Step [300/938], Reconst Loss: 15194.9531\n",
      "Epoch[4/20], Step [400/938], Reconst Loss: 16353.4883\n",
      "Epoch[4/20], Step [500/938], Reconst Loss: 16271.8486\n",
      "Epoch[4/20], Step [600/938], Reconst Loss: 15922.9570\n",
      "Epoch[4/20], Step [700/938], Reconst Loss: 15756.8438\n",
      "Epoch[4/20], Step [800/938], Reconst Loss: 15121.0820\n",
      "Epoch[4/20], Step [900/938], Reconst Loss: 14665.8555\n",
      "Epoch[5/20], Step [100/938], Reconst Loss: 16150.5254\n",
      "Epoch[5/20], Step [200/938], Reconst Loss: 16814.8320\n",
      "Epoch[5/20], Step [300/938], Reconst Loss: 15337.9258\n",
      "Epoch[5/20], Step [400/938], Reconst Loss: 14958.5869\n",
      "Epoch[5/20], Step [500/938], Reconst Loss: 14571.0527\n",
      "Epoch[5/20], Step [600/938], Reconst Loss: 15659.8945\n",
      "Epoch[5/20], Step [700/938], Reconst Loss: 15579.9219\n",
      "Epoch[5/20], Step [800/938], Reconst Loss: 16371.9180\n",
      "Epoch[5/20], Step [900/938], Reconst Loss: 15384.8398\n",
      "Epoch[6/20], Step [100/938], Reconst Loss: 14965.7109\n",
      "Epoch[6/20], Step [200/938], Reconst Loss: 15641.3457\n",
      "Epoch[6/20], Step [300/938], Reconst Loss: 14794.5918\n",
      "Epoch[6/20], Step [400/938], Reconst Loss: 15833.5234\n",
      "Epoch[6/20], Step [500/938], Reconst Loss: 15724.0059\n",
      "Epoch[6/20], Step [600/938], Reconst Loss: 15766.0986\n",
      "Epoch[6/20], Step [700/938], Reconst Loss: 15209.5586\n",
      "Epoch[6/20], Step [800/938], Reconst Loss: 13462.4590\n",
      "Epoch[6/20], Step [900/938], Reconst Loss: 15084.0400\n",
      "Epoch[7/20], Step [100/938], Reconst Loss: 15733.4756\n",
      "Epoch[7/20], Step [200/938], Reconst Loss: 16375.2695\n",
      "Epoch[7/20], Step [300/938], Reconst Loss: 14866.2832\n",
      "Epoch[7/20], Step [400/938], Reconst Loss: 16157.1035\n",
      "Epoch[7/20], Step [500/938], Reconst Loss: 14341.2861\n",
      "Epoch[7/20], Step [600/938], Reconst Loss: 14896.7920\n",
      "Epoch[7/20], Step [700/938], Reconst Loss: 15610.6143\n",
      "Epoch[7/20], Step [800/938], Reconst Loss: 15063.2480\n",
      "Epoch[7/20], Step [900/938], Reconst Loss: 15528.1738\n",
      "Epoch[8/20], Step [100/938], Reconst Loss: 15914.4004\n",
      "Epoch[8/20], Step [200/938], Reconst Loss: 14637.9668\n",
      "Epoch[8/20], Step [300/938], Reconst Loss: 14255.6328\n",
      "Epoch[8/20], Step [400/938], Reconst Loss: 14763.4023\n",
      "Epoch[8/20], Step [500/938], Reconst Loss: 15502.3252\n",
      "Epoch[8/20], Step [600/938], Reconst Loss: 15187.4199\n",
      "Epoch[8/20], Step [700/938], Reconst Loss: 13925.0938\n",
      "Epoch[8/20], Step [800/938], Reconst Loss: 14608.0293\n",
      "Epoch[8/20], Step [900/938], Reconst Loss: 15719.6543\n",
      "Epoch[9/20], Step [100/938], Reconst Loss: 15446.8350\n",
      "Epoch[9/20], Step [200/938], Reconst Loss: 15103.4502\n",
      "Epoch[9/20], Step [300/938], Reconst Loss: 14728.7881\n",
      "Epoch[9/20], Step [400/938], Reconst Loss: 13649.7334\n",
      "Epoch[9/20], Step [500/938], Reconst Loss: 14081.3242\n",
      "Epoch[9/20], Step [600/938], Reconst Loss: 14535.3828\n",
      "Epoch[9/20], Step [700/938], Reconst Loss: 14602.9922\n",
      "Epoch[9/20], Step [800/938], Reconst Loss: 14031.5752\n",
      "Epoch[9/20], Step [900/938], Reconst Loss: 15089.0752\n",
      "Epoch[10/20], Step [100/938], Reconst Loss: 15820.9824\n",
      "Epoch[10/20], Step [200/938], Reconst Loss: 14323.0039\n",
      "Epoch[10/20], Step [300/938], Reconst Loss: 14445.4160\n",
      "Epoch[10/20], Step [400/938], Reconst Loss: 14812.5742\n",
      "Epoch[10/20], Step [500/938], Reconst Loss: 14431.6250\n",
      "Epoch[10/20], Step [600/938], Reconst Loss: 15734.2871\n",
      "Epoch[10/20], Step [700/938], Reconst Loss: 14005.3438\n",
      "Epoch[10/20], Step [800/938], Reconst Loss: 14479.8350\n",
      "Epoch[10/20], Step [900/938], Reconst Loss: 15064.9434\n",
      "Epoch[11/20], Step [100/938], Reconst Loss: 14873.3564\n",
      "Epoch[11/20], Step [200/938], Reconst Loss: 14801.2520\n",
      "Epoch[11/20], Step [300/938], Reconst Loss: 16000.6777\n",
      "Epoch[11/20], Step [400/938], Reconst Loss: 15537.1602\n",
      "Epoch[11/20], Step [500/938], Reconst Loss: 15324.0469\n",
      "Epoch[11/20], Step [600/938], Reconst Loss: 15068.4590\n",
      "Epoch[11/20], Step [700/938], Reconst Loss: 14319.7354\n",
      "Epoch[11/20], Step [800/938], Reconst Loss: 14640.5352\n",
      "Epoch[11/20], Step [900/938], Reconst Loss: 14834.2754\n",
      "Epoch[12/20], Step [100/938], Reconst Loss: 14705.8623\n",
      "Epoch[12/20], Step [200/938], Reconst Loss: 15243.2773\n",
      "Epoch[12/20], Step [300/938], Reconst Loss: 13566.4209\n",
      "Epoch[12/20], Step [400/938], Reconst Loss: 14644.7783\n",
      "Epoch[12/20], Step [500/938], Reconst Loss: 14536.1660\n",
      "Epoch[12/20], Step [600/938], Reconst Loss: 14991.9609\n",
      "Epoch[12/20], Step [700/938], Reconst Loss: 14773.8906\n",
      "Epoch[12/20], Step [800/938], Reconst Loss: 14487.4248\n",
      "Epoch[12/20], Step [900/938], Reconst Loss: 15031.7119\n",
      "Epoch[13/20], Step [100/938], Reconst Loss: 15028.8516\n",
      "Epoch[13/20], Step [200/938], Reconst Loss: 14997.6621\n",
      "Epoch[13/20], Step [300/938], Reconst Loss: 14826.9355\n",
      "Epoch[13/20], Step [400/938], Reconst Loss: 14029.8203\n",
      "Epoch[13/20], Step [500/938], Reconst Loss: 13854.8799\n",
      "Epoch[13/20], Step [600/938], Reconst Loss: 14795.0098\n",
      "Epoch[13/20], Step [700/938], Reconst Loss: 16117.0088\n",
      "Epoch[13/20], Step [800/938], Reconst Loss: 15541.0820\n",
      "Epoch[13/20], Step [900/938], Reconst Loss: 15128.0703\n",
      "Epoch[14/20], Step [100/938], Reconst Loss: 14629.4541\n",
      "Epoch[14/20], Step [200/938], Reconst Loss: 14124.1016\n",
      "Epoch[14/20], Step [300/938], Reconst Loss: 14855.1621\n",
      "Epoch[14/20], Step [400/938], Reconst Loss: 15241.2930\n",
      "Epoch[14/20], Step [500/938], Reconst Loss: 14532.4834\n",
      "Epoch[14/20], Step [600/938], Reconst Loss: 15333.1348\n",
      "Epoch[14/20], Step [700/938], Reconst Loss: 16092.3271\n",
      "Epoch[14/20], Step [800/938], Reconst Loss: 15766.2441\n",
      "Epoch[14/20], Step [900/938], Reconst Loss: 14731.9912\n",
      "Epoch[15/20], Step [100/938], Reconst Loss: 13446.9082\n",
      "Epoch[15/20], Step [200/938], Reconst Loss: 13939.2051\n",
      "Epoch[15/20], Step [300/938], Reconst Loss: 14335.3379\n",
      "Epoch[15/20], Step [400/938], Reconst Loss: 15546.0742\n",
      "Epoch[15/20], Step [500/938], Reconst Loss: 13883.9424\n",
      "Epoch[15/20], Step [600/938], Reconst Loss: 13438.1748\n",
      "Epoch[15/20], Step [700/938], Reconst Loss: 14638.0684\n",
      "Epoch[15/20], Step [800/938], Reconst Loss: 14599.9258\n",
      "Epoch[15/20], Step [900/938], Reconst Loss: 15190.5088\n",
      "Epoch[16/20], Step [100/938], Reconst Loss: 15234.8047\n",
      "Epoch[16/20], Step [200/938], Reconst Loss: 15660.9756\n",
      "Epoch[16/20], Step [300/938], Reconst Loss: 15336.1963\n",
      "Epoch[16/20], Step [400/938], Reconst Loss: 15352.7412\n",
      "Epoch[16/20], Step [500/938], Reconst Loss: 14786.6631\n",
      "Epoch[16/20], Step [600/938], Reconst Loss: 14531.8047\n",
      "Epoch[16/20], Step [700/938], Reconst Loss: 13403.2646\n",
      "Epoch[16/20], Step [800/938], Reconst Loss: 13892.6094\n",
      "Epoch[16/20], Step [900/938], Reconst Loss: 15191.5293\n",
      "Epoch[17/20], Step [100/938], Reconst Loss: 14568.5742\n",
      "Epoch[17/20], Step [200/938], Reconst Loss: 15211.1602\n",
      "Epoch[17/20], Step [300/938], Reconst Loss: 14030.3691\n",
      "Epoch[17/20], Step [400/938], Reconst Loss: 15310.1094\n",
      "Epoch[17/20], Step [500/938], Reconst Loss: 15253.2305\n",
      "Epoch[17/20], Step [600/938], Reconst Loss: 14714.9297\n",
      "Epoch[17/20], Step [700/938], Reconst Loss: 13652.9932\n",
      "Epoch[17/20], Step [800/938], Reconst Loss: 14940.1328\n",
      "Epoch[17/20], Step [900/938], Reconst Loss: 14697.6367\n",
      "Epoch[18/20], Step [100/938], Reconst Loss: 14639.2461\n",
      "Epoch[18/20], Step [200/938], Reconst Loss: 14288.4668\n",
      "Epoch[18/20], Step [300/938], Reconst Loss: 15546.8154\n",
      "Epoch[18/20], Step [400/938], Reconst Loss: 14528.1123\n",
      "Epoch[18/20], Step [500/938], Reconst Loss: 15142.2812\n",
      "Epoch[18/20], Step [600/938], Reconst Loss: 14146.4004\n",
      "Epoch[18/20], Step [700/938], Reconst Loss: 14852.2031\n",
      "Epoch[18/20], Step [800/938], Reconst Loss: 15281.4199\n",
      "Epoch[18/20], Step [900/938], Reconst Loss: 14542.2002\n",
      "Epoch[19/20], Step [100/938], Reconst Loss: 15210.6211\n",
      "Epoch[19/20], Step [200/938], Reconst Loss: 14255.4824\n",
      "Epoch[19/20], Step [300/938], Reconst Loss: 15301.8779\n",
      "Epoch[19/20], Step [400/938], Reconst Loss: 14463.0254\n",
      "Epoch[19/20], Step [500/938], Reconst Loss: 15223.1836\n",
      "Epoch[19/20], Step [600/938], Reconst Loss: 14582.4443\n",
      "Epoch[19/20], Step [700/938], Reconst Loss: 15133.8320\n",
      "Epoch[19/20], Step [800/938], Reconst Loss: 14721.8291\n",
      "Epoch[19/20], Step [900/938], Reconst Loss: 14141.6777\n",
      "Epoch[20/20], Step [100/938], Reconst Loss: 14938.2314\n",
      "Epoch[20/20], Step [200/938], Reconst Loss: 13930.6328\n",
      "Epoch[20/20], Step [300/938], Reconst Loss: 14699.8799\n",
      "Epoch[20/20], Step [400/938], Reconst Loss: 14426.6162\n",
      "Epoch[20/20], Step [500/938], Reconst Loss: 14585.0586\n",
      "Epoch[20/20], Step [600/938], Reconst Loss: 14226.2383\n",
      "Epoch[20/20], Step [700/938], Reconst Loss: 15361.6426\n",
      "Epoch[20/20], Step [800/938], Reconst Loss: 14989.2676\n",
      "Epoch[20/20], Step [900/938], Reconst Loss: 14669.0605\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "\n",
    "        x = x.to(device).view(-1, 784)\n",
    "        x_reconst, mu, log_var = vaeModel(x)\n",
    "        \n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch[{}/{}],Reconst Loss: {:.4f}\".format(epoch+1, 20,reconst_loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out, _, _ = vaeModel(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join('imagesAfterVAE', 'new-{}.png'.format(epoch+1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffde22c7e3ab4ff93e377892df1322fd8c587e5b72d92c17c00ab05441ad7327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
