{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 开启gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) # cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据集\n",
    "dataset = FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义变分自编码器\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc2 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(400, 20)\n",
    "        self.fc4 = nn.Linear(20, 400)\n",
    "        self.fc5 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "\n",
    "vaeModel = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vaeModel.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20],Reconst Loss: 24479.9473\n",
      "Epoch[1/20],Reconst Loss: 21513.4297\n",
      "Epoch[1/20],Reconst Loss: 20585.4922\n",
      "Epoch[1/20],Reconst Loss: 18553.8828\n",
      "Epoch[1/20],Reconst Loss: 17870.0391\n",
      "Epoch[1/20],Reconst Loss: 19336.3418\n",
      "Epoch[1/20],Reconst Loss: 17340.0254\n",
      "Epoch[1/20],Reconst Loss: 17771.6758\n",
      "Epoch[1/20],Reconst Loss: 16845.7344\n",
      "Epoch[2/20],Reconst Loss: 16551.6328\n",
      "Epoch[2/20],Reconst Loss: 16829.4922\n",
      "Epoch[2/20],Reconst Loss: 16932.4824\n",
      "Epoch[2/20],Reconst Loss: 16275.6807\n",
      "Epoch[2/20],Reconst Loss: 15964.1123\n",
      "Epoch[2/20],Reconst Loss: 16183.8105\n",
      "Epoch[2/20],Reconst Loss: 15656.6318\n",
      "Epoch[2/20],Reconst Loss: 15983.4941\n",
      "Epoch[2/20],Reconst Loss: 15815.7471\n",
      "Epoch[3/20],Reconst Loss: 16181.8027\n",
      "Epoch[3/20],Reconst Loss: 16147.0557\n",
      "Epoch[3/20],Reconst Loss: 15249.6562\n",
      "Epoch[3/20],Reconst Loss: 16408.1953\n",
      "Epoch[3/20],Reconst Loss: 15418.3320\n",
      "Epoch[3/20],Reconst Loss: 15978.2480\n",
      "Epoch[3/20],Reconst Loss: 16167.6992\n",
      "Epoch[3/20],Reconst Loss: 16204.2617\n",
      "Epoch[3/20],Reconst Loss: 14011.7354\n",
      "Epoch[4/20],Reconst Loss: 14886.5967\n",
      "Epoch[4/20],Reconst Loss: 15277.3564\n",
      "Epoch[4/20],Reconst Loss: 15703.3652\n",
      "Epoch[4/20],Reconst Loss: 14647.5615\n",
      "Epoch[4/20],Reconst Loss: 16123.3691\n",
      "Epoch[4/20],Reconst Loss: 15186.3633\n",
      "Epoch[4/20],Reconst Loss: 15490.1992\n",
      "Epoch[4/20],Reconst Loss: 15567.5264\n",
      "Epoch[4/20],Reconst Loss: 15658.7695\n",
      "Epoch[5/20],Reconst Loss: 15513.0020\n",
      "Epoch[5/20],Reconst Loss: 14223.9258\n",
      "Epoch[5/20],Reconst Loss: 15940.7070\n",
      "Epoch[5/20],Reconst Loss: 16527.6914\n",
      "Epoch[5/20],Reconst Loss: 14676.1211\n",
      "Epoch[5/20],Reconst Loss: 15438.5898\n",
      "Epoch[5/20],Reconst Loss: 14559.2168\n",
      "Epoch[5/20],Reconst Loss: 15179.1035\n",
      "Epoch[5/20],Reconst Loss: 15947.1953\n",
      "Epoch[6/20],Reconst Loss: 16081.4053\n",
      "Epoch[6/20],Reconst Loss: 16409.4570\n",
      "Epoch[6/20],Reconst Loss: 14924.5957\n",
      "Epoch[6/20],Reconst Loss: 15649.7480\n",
      "Epoch[6/20],Reconst Loss: 16116.1270\n",
      "Epoch[6/20],Reconst Loss: 14116.5996\n",
      "Epoch[6/20],Reconst Loss: 15547.0801\n",
      "Epoch[6/20],Reconst Loss: 16057.3770\n",
      "Epoch[6/20],Reconst Loss: 15838.2832\n",
      "Epoch[7/20],Reconst Loss: 15009.3574\n",
      "Epoch[7/20],Reconst Loss: 14920.4277\n",
      "Epoch[7/20],Reconst Loss: 14938.6650\n",
      "Epoch[7/20],Reconst Loss: 14950.3066\n",
      "Epoch[7/20],Reconst Loss: 14595.3887\n",
      "Epoch[7/20],Reconst Loss: 14382.3770\n",
      "Epoch[7/20],Reconst Loss: 14530.8867\n",
      "Epoch[7/20],Reconst Loss: 15801.5703\n",
      "Epoch[7/20],Reconst Loss: 16359.9805\n",
      "Epoch[8/20],Reconst Loss: 14813.8418\n",
      "Epoch[8/20],Reconst Loss: 14540.6025\n",
      "Epoch[8/20],Reconst Loss: 15849.8086\n",
      "Epoch[8/20],Reconst Loss: 15631.8984\n",
      "Epoch[8/20],Reconst Loss: 14918.4639\n",
      "Epoch[8/20],Reconst Loss: 14956.1318\n",
      "Epoch[8/20],Reconst Loss: 15843.7168\n",
      "Epoch[8/20],Reconst Loss: 15764.2148\n",
      "Epoch[8/20],Reconst Loss: 15205.4121\n",
      "Epoch[9/20],Reconst Loss: 15325.2031\n",
      "Epoch[9/20],Reconst Loss: 15335.7324\n",
      "Epoch[9/20],Reconst Loss: 15022.4941\n",
      "Epoch[9/20],Reconst Loss: 15048.6562\n",
      "Epoch[9/20],Reconst Loss: 15287.8887\n",
      "Epoch[9/20],Reconst Loss: 15172.6348\n",
      "Epoch[9/20],Reconst Loss: 14118.4648\n",
      "Epoch[9/20],Reconst Loss: 14407.5449\n",
      "Epoch[9/20],Reconst Loss: 15045.8086\n",
      "Epoch[10/20],Reconst Loss: 15684.6523\n",
      "Epoch[10/20],Reconst Loss: 15575.8262\n",
      "Epoch[10/20],Reconst Loss: 15108.2637\n",
      "Epoch[10/20],Reconst Loss: 15673.1553\n",
      "Epoch[10/20],Reconst Loss: 14464.6895\n",
      "Epoch[10/20],Reconst Loss: 15413.7266\n",
      "Epoch[10/20],Reconst Loss: 15389.4941\n",
      "Epoch[10/20],Reconst Loss: 14985.9062\n",
      "Epoch[10/20],Reconst Loss: 13890.5527\n",
      "Epoch[11/20],Reconst Loss: 14465.0547\n",
      "Epoch[11/20],Reconst Loss: 15873.6709\n",
      "Epoch[11/20],Reconst Loss: 14462.1016\n",
      "Epoch[11/20],Reconst Loss: 15704.4141\n",
      "Epoch[11/20],Reconst Loss: 14955.6445\n",
      "Epoch[11/20],Reconst Loss: 13819.9277\n",
      "Epoch[11/20],Reconst Loss: 15209.6602\n",
      "Epoch[11/20],Reconst Loss: 14418.8984\n",
      "Epoch[11/20],Reconst Loss: 14570.1523\n",
      "Epoch[12/20],Reconst Loss: 14882.5107\n",
      "Epoch[12/20],Reconst Loss: 15116.2910\n",
      "Epoch[12/20],Reconst Loss: 16109.9453\n",
      "Epoch[12/20],Reconst Loss: 14903.9326\n",
      "Epoch[12/20],Reconst Loss: 15258.6484\n",
      "Epoch[12/20],Reconst Loss: 15106.3369\n",
      "Epoch[12/20],Reconst Loss: 15179.8281\n",
      "Epoch[12/20],Reconst Loss: 14569.4473\n",
      "Epoch[12/20],Reconst Loss: 13870.4668\n",
      "Epoch[13/20],Reconst Loss: 14997.0957\n",
      "Epoch[13/20],Reconst Loss: 15070.9336\n",
      "Epoch[13/20],Reconst Loss: 15350.5449\n",
      "Epoch[13/20],Reconst Loss: 14748.5059\n",
      "Epoch[13/20],Reconst Loss: 14499.8633\n",
      "Epoch[13/20],Reconst Loss: 14310.8027\n",
      "Epoch[13/20],Reconst Loss: 14612.9648\n",
      "Epoch[13/20],Reconst Loss: 14683.1445\n",
      "Epoch[13/20],Reconst Loss: 14455.9043\n",
      "Epoch[14/20],Reconst Loss: 15147.6143\n",
      "Epoch[14/20],Reconst Loss: 14261.4785\n",
      "Epoch[14/20],Reconst Loss: 15675.5801\n",
      "Epoch[14/20],Reconst Loss: 14544.5527\n",
      "Epoch[14/20],Reconst Loss: 15311.8926\n",
      "Epoch[14/20],Reconst Loss: 15415.6846\n",
      "Epoch[14/20],Reconst Loss: 14466.0879\n",
      "Epoch[14/20],Reconst Loss: 15126.6328\n",
      "Epoch[14/20],Reconst Loss: 14314.5566\n",
      "Epoch[15/20],Reconst Loss: 14515.4531\n",
      "Epoch[15/20],Reconst Loss: 14704.2168\n",
      "Epoch[15/20],Reconst Loss: 14849.7930\n",
      "Epoch[15/20],Reconst Loss: 14229.8848\n",
      "Epoch[15/20],Reconst Loss: 14162.0781\n",
      "Epoch[15/20],Reconst Loss: 14048.2529\n",
      "Epoch[15/20],Reconst Loss: 15902.2422\n",
      "Epoch[15/20],Reconst Loss: 15189.1123\n",
      "Epoch[15/20],Reconst Loss: 14682.3477\n",
      "Epoch[16/20],Reconst Loss: 14008.1504\n",
      "Epoch[16/20],Reconst Loss: 14446.6455\n",
      "Epoch[16/20],Reconst Loss: 14947.1406\n",
      "Epoch[16/20],Reconst Loss: 14509.0596\n",
      "Epoch[16/20],Reconst Loss: 14185.5020\n",
      "Epoch[16/20],Reconst Loss: 15468.8223\n",
      "Epoch[16/20],Reconst Loss: 15178.5791\n",
      "Epoch[16/20],Reconst Loss: 14871.2129\n",
      "Epoch[16/20],Reconst Loss: 13758.0273\n",
      "Epoch[17/20],Reconst Loss: 13677.0820\n",
      "Epoch[17/20],Reconst Loss: 14591.9121\n",
      "Epoch[17/20],Reconst Loss: 14691.8926\n",
      "Epoch[17/20],Reconst Loss: 14742.3203\n",
      "Epoch[17/20],Reconst Loss: 14707.0049\n",
      "Epoch[17/20],Reconst Loss: 13850.0195\n",
      "Epoch[17/20],Reconst Loss: 14718.0264\n",
      "Epoch[17/20],Reconst Loss: 15174.4922\n",
      "Epoch[17/20],Reconst Loss: 14859.3652\n",
      "Epoch[18/20],Reconst Loss: 15925.6250\n",
      "Epoch[18/20],Reconst Loss: 14375.8008\n",
      "Epoch[18/20],Reconst Loss: 15052.3887\n",
      "Epoch[18/20],Reconst Loss: 15792.1348\n",
      "Epoch[18/20],Reconst Loss: 14236.2891\n",
      "Epoch[18/20],Reconst Loss: 14246.6855\n",
      "Epoch[18/20],Reconst Loss: 15386.9111\n",
      "Epoch[18/20],Reconst Loss: 14574.5352\n",
      "Epoch[18/20],Reconst Loss: 14831.2891\n",
      "Epoch[19/20],Reconst Loss: 14766.2480\n",
      "Epoch[19/20],Reconst Loss: 14769.8750\n",
      "Epoch[19/20],Reconst Loss: 14995.6377\n",
      "Epoch[19/20],Reconst Loss: 14910.5801\n",
      "Epoch[19/20],Reconst Loss: 14083.4014\n",
      "Epoch[19/20],Reconst Loss: 15333.4160\n",
      "Epoch[19/20],Reconst Loss: 14346.4375\n",
      "Epoch[19/20],Reconst Loss: 14455.2256\n",
      "Epoch[19/20],Reconst Loss: 15261.0000\n",
      "Epoch[20/20],Reconst Loss: 15267.0703\n",
      "Epoch[20/20],Reconst Loss: 13739.5391\n",
      "Epoch[20/20],Reconst Loss: 13390.5117\n",
      "Epoch[20/20],Reconst Loss: 14746.2480\n",
      "Epoch[20/20],Reconst Loss: 12208.5117\n",
      "Epoch[20/20],Reconst Loss: 14068.0547\n",
      "Epoch[20/20],Reconst Loss: 13199.7168\n",
      "Epoch[20/20],Reconst Loss: 14652.0371\n",
      "Epoch[20/20],Reconst Loss: 15350.1328\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "\n",
    "        x = x.to(device).view(-1, 784)\n",
    "        x_reconst, mu, log_var = vaeModel(x)\n",
    "        \n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch[{}/{}],Reconst Loss: {:.4f}\".format(epoch+1, 20,reconst_loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out, _, _ = vaeModel(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join('imagesAfterVAE', 'new-{}.png'.format(epoch+1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffde22c7e3ab4ff93e377892df1322fd8c587e5b72d92c17c00ab05441ad7327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
